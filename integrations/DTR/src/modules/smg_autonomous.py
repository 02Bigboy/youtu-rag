"""
SMG Autonomous Module - è‡ªä¸»å¾ªç¯ä»£ç ç”Ÿæˆ

æ ¸å¿ƒæ”¹è¿›ï¼š
1. å‚è€ƒADOæå–çš„operatoråºåˆ—ï¼ˆä½œä¸ºæŒ‡å¯¼ï¼‰
2. ä½¿ç”¨LLMè‡ªä¸»å¾ªç¯ï¼Œè®©LLMè‡ªå·±å†³å®šä½•æ—¶[THINK]/[CODE]/[Final Answer]
3. æœ€å¤§10è½®è¿­ä»£ï¼Œè¶…æ—¶å¼ºåˆ¶ç»“æŸ
4. å……åˆ†åˆ©ç”¨LLMçš„æ¨ç†å’Œè§„åˆ’èƒ½åŠ›
"""

import time
import re
import json
from typing import List, Dict, Any, Optional, Tuple
import pandas as pd
from datetime import datetime
import sys
from pathlib import Path

project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))
from src.core.dtr_structures import (
    Operator, ExecutionPath, TableState, SMGNode, RewardVector
)


class SMGAutonomousModule:
    """
    è‡ªä¸»å¾ªç¯SMGæ¨¡å—
    
    æ ¸å¿ƒæ€æƒ³ï¼š
    - ADOæä¾›operatoråºåˆ—ä½œä¸ºå‚è€ƒï¼ˆè€Œéå¼ºåˆ¶æ‰§è¡Œï¼‰
    - LLMè‡ªä¸»å†³ç­–æ¯ä¸€æ­¥ï¼šæ€è€ƒã€å†™ä»£ç ã€æˆ–è¾“å‡ºç­”æ¡ˆ
    - æ¯æ¬¡å¯ä»¥è¾“å‡º[THINK]/[CODE]/[Final Answer]æ ‡è¯†
    - æœ€å¤š10è½®è¿­ä»£
    """
    
    def __init__(self, llm_client, event_callback, reward_evaluator):
        self.llm_client = llm_client
        self.reward_evaluator = reward_evaluator
        self.event_callback = event_callback  # æ·»åŠ äº‹ä»¶å›è°ƒ
        self.memory: List[SMGNode] = []
        self.persistent_memory: Dict[str, List[SMGNode]] = {}
    
    def _emit_event(self, name: str, event_data: Dict[str, Any]):
        """å‘é€äº‹ä»¶åˆ°å›è°ƒå‡½æ•°"""
        if self.event_callback:
            try:
                self.event_callback(name, event_data)
            except Exception as e:
                logger.warning(f"Failed to emit event: {e}")
    
    def execute_with_autonomous_loop(
        self,
        operator_sequence: List[str],  # ADOæå–çš„operatoråºåˆ—(ä½œä¸ºå‚è€ƒ)
        operator_pool: List[Operator],  # å®Œæ•´çš„operatoræ± 
        dataframe: pd.DataFrame,
        user_query: str,
        table_metadata: Dict[str, Any],
        schema_result=None,
        max_iterations: int = 10
    ) -> Dict[str, Any]:
        """
        è‡ªä¸»å¾ªç¯æ‰§è¡Œ
        
        æµç¨‹ï¼š
        1. æ„å»ºåˆå§‹contextï¼ˆåŒ…å«operatoråºåˆ—ä½œä¸ºå‚è€ƒï¼‰
        2. è¿›å…¥è‡ªä¸»å¾ªç¯ï¼ˆæœ€å¤šmax_iterationsè½®ï¼‰
        3. æ¯è½®LLMå¯ä»¥ï¼š
           - [THINK]: åˆ†æå½“å‰çŠ¶æ€ï¼Œè§„åˆ’ä¸‹ä¸€æ­¥
           - [CODE]: ç”Ÿæˆå¹¶æ‰§è¡Œä»£ç 
           - [Final Answer]: è¾“å‡ºæœ€ç»ˆç­”æ¡ˆï¼Œç»“æŸ
        4. è¾¾åˆ°ä¸Šé™åå¼ºåˆ¶ç»“æŸ
        
        Args:
            operator_sequence: ADOæå–çš„operatoråç§°åˆ—è¡¨(ä½œä¸ºå‚è€ƒæŒ‡å¯¼)
            operator_pool: å®Œæ•´çš„operatorå®šä¹‰æ± 
            dataframe: è¾“å…¥æ•°æ®
            user_query: ç”¨æˆ·é—®é¢˜
            table_metadata: è¡¨æ ¼å…ƒæ•°æ®
            schema_result: Schemaä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
        
        Returns:
            Dict with:
                - final_df: æœ€ç»ˆç»“æœDataFrame
                - final_answer: è‡ªç„¶è¯­è¨€ç­”æ¡ˆ
                - execution_trace: æ‰§è¡Œè½¨è¿¹
                - memory_nodes: SMGèŠ‚ç‚¹
                - iterations_used: å®é™…ä½¿ç”¨çš„è¿­ä»£æ¬¡æ•°
        """
        
        plan_str = "\n\n"
        plan_str += f"ğŸ”„ AUTONOMOUS LOOP EXECUTION (max {max_iterations} iterations)\n"
        plan_str += f"ğŸ“‹ Reference Operator Sequence: {' â†’ '.join(operator_sequence)}\n"
        plan_str += f"   (LLM can follow or deviate based on its judgment)\n"

        self._emit_event(
            name="excel_agent.plan.delta",
            event_data={
                "content": plan_str
            }
        )

        self._emit_event(
            name="excel_agent.plan.done",
            event_data={
                "content": "<plan_done>"
            }
        )
        
        # æ„å»ºoperatorä¿¡æ¯å­—å…¸
        operator_map = {op.name: op for op in operator_pool}
        
        # æ„å»ºåˆå§‹prompt
        initial_prompt = self._build_initial_prompt(
            user_query=user_query,
            dataframe=dataframe,
            operator_sequence=operator_sequence,
            operator_map=operator_map,
            table_metadata=table_metadata,
            schema_result=schema_result
        )
        
        # å¯¹è¯å†å²
        conversation_history = [initial_prompt]
        
        # æ‰§è¡ŒçŠ¶æ€
        current_df = dataframe.copy()
        execution_trace = []
        code_executions = []  # è®°å½•æ‰€æœ‰ä»£ç æ‰§è¡Œ
        
        # è‡ªä¸»å¾ªç¯
        for iteration in range(max_iterations):

            self._emit_event(
                name="excel_agent.task.start",
                event_data={
                    "type": "reasoning",
                    "operation": f"Iteration {iteration + 1}/{max_iterations}",
                    "content": "<reasoning_start>"
                }
            )
            
            # è°ƒç”¨LLM (æå‡max_tokensä»¥å…è®¸è¯¦ç»†åˆ†æ)
            current_input = self._format_conversation(conversation_history)
            try:
                response = self.llm_client.call_api(current_input, max_tokens=3072)  # æå‡åˆ°3072ï¼Œå¹³è¡¡è´¨é‡å’Œé€Ÿåº¦
            except Exception as e:
                print(f"âŒ LLM call failed: {e}")
                break
            
            # è®°å½•response
            conversation_history.append(f"\n## Assistant Response (Round {iteration + 1})\n{response}")
            
            # è§£æresponseï¼Œæ£€æµ‹æ ‡è¯†
            action, content = self._parse_response_action(response)
            
            print(f"ğŸ¯ Detected action: {action}")
            
            if action == "FINAL_ANSWER":
                # æ‰¾åˆ°æœ€ç»ˆç­”æ¡ˆï¼Œç»“æŸå¾ªç¯
                final_answer = self._extract_final_answer(response)
                print(f"âœ… Final answer reached at iteration {iteration + 1}")
                print(f"   Answer: {final_answer[:100]}...")

                self._emit_event(
                    name="excel_agent.task.done",
                    event_data={
                        "type": "final answer",
                        "operation": f"[{action}]",
                        "content": "Finished"
                    }
                )
                
                return {
                    "final_df": current_df,
                    "final_answer": final_answer,
                    "execution_trace": execution_trace,
                    "memory_nodes": self.memory,
                    "iterations_used": iteration + 1,
                    "code_executions": code_executions,
                    "success": True
                }
            
            elif action == "CODE":
                # æå–å¹¶æ‰§è¡Œä»£ç 
                code = self._extract_code_block(content)
                
                if not code or code.strip() == "pass":
                    print(f"âš ï¸  No valid code extracted, prompting LLM...")
                    feedback = "No code was extracted. Please provide valid Python code in [CODE] block."
                    conversation_history.append(f"\n## System Feedback\n{feedback}")
                    continue
                
                print(f"ğŸ”§ Executing code...")
                print(f"   Code preview: {code[:100]}...")

                self._emit_event(
                    name="excel_agent.task.delta",
                    event_data={
                        "type": "code_generation",
                        "operation": f"[{action}]",
                        "content": f"{code}",
                        "mode": "code",
                        "clean": True
                    }
                )
                
                # æ‰§è¡Œä»£ç 
                start_time = time.time()
                exec_result = self._execute_code_safe(code, current_df)
                execution_time = time.time() - start_time
                
                success = exec_result["success"]
                error_msg = exec_result.get("error", "")
                
                # è®°å½•æ‰§è¡Œ
                code_executions.append({
                    "iteration": iteration + 1,
                    "code": code,
                    "success": success,
                    "error": error_msg,
                    "execution_time": execution_time
                })
                
                if success:
                    # æ›´æ–°current_df
                    current_df = exec_result["dataframe"]
                    print(f"   âœ… Execution succeeded")
                    print(f"   Result shape: {current_df.shape}")
                    
                    # æ„å»ºæˆåŠŸåé¦ˆ
                    feedback = self._build_success_feedback(exec_result, current_df)
                    conversation_history.append(feedback)
                    
                    # æ·»åŠ åˆ°execution trace
                    execution_trace.append({
                        "iteration": iteration + 1,
                        "action": "CODE_EXECUTION",
                        "code": code,
                        "success": True,
                        "result_shape": current_df.shape
                    })

                    self._emit_event(
                        name="excel_agent.task.done",
                        event_data={
                            "type": "code_execution",
                            "operation": f"[{action}] | âœ… Execution Success",
                            "content": f"âœ… Execution Success: (Shape: {current_df.shape if isinstance(current_df, pd.DataFrame) else 'N/A'})"
                        }
                    )

                    task_type = "code_execution"
                    operation = f"[{action}] | âœ… Execution Success"
                    
                else:
                    # æ‰§è¡Œå¤±è´¥
                    print(f"   âŒ Execution failed: {error_msg[:100]}")
                    
                    # æ„å»ºé”™è¯¯åé¦ˆ
                    feedback = self._build_error_feedback(exec_result)
                    conversation_history.append(feedback)
                    
                    # æ·»åŠ åˆ°execution trace
                    execution_trace.append({
                        "iteration": iteration + 1,
                        "action": "CODE_EXECUTION",
                        "code": code,
                        "success": False,
                        "error": error_msg
                    })

                    self._emit_event(
                        name="excel_agent.task.done",
                        event_data={
                            "type": "code_execution",
                            "operation": f"{action} | âŒ Execution Failed:ã€Œ{error_msg[:50]}...ã€",
                            "content": f"âŒ Execution Failed: {error_msg}"
                        }
                    )

                    task_type = "code_execution"
                    operation = f"[{action}] | âŒ Execution Failed"
            
            elif action == "THINK":
                # LLMåœ¨æ€è€ƒï¼Œè®°å½•å¹¶ç»§ç»­
                print(f"ğŸ’­ LLM is thinking/reflecting...")
                thought = self._extract_think_content(content)
                print(f"   Thought: {thought[:150]}...")

                self._emit_event(
                    name="excel_agent.task.delta",
                    event_data={
                        "type": "reflection",
                        "operation": f"[{action}]",
                        "content": f"{thought}",
                        "clean": True
                    }
                )

                task_type = "reflection"
                operation = f"[{action}]"
                
                # è®°å½•æ€è€ƒ
                execution_trace.append({
                    "iteration": iteration + 1,
                    "action": "THINK",
                    "content": thought
                })
                
                # æç¤ºç»§ç»­
                continuation = """
Good thinking! Based on your analysis, what's your next step?

You can:
- Use **[CODE]** to write and execute code
- Use **[THINK]** to continue analyzing
- Use **[Final Answer]** if you have the complete answer

What would you like to do?
"""
                conversation_history.append(continuation)
            
            else:
                # æ²¡æœ‰æ˜ç¡®æ ‡è¯†ï¼Œæé†’ä½¿ç”¨æ ‡è¯†
                print(f"âš ï¸  No clear action tag detected, reminding LLM...")

                self._emit_event(
                    name="excel_agent.task.delta",
                    event_data={
                        "type": "reflection",
                        "operation": f"[{action}]",
                        "content": f"âš ï¸  No clear action tag detected, reminding LLM...",
                        "clean": True
                    }
                )

                task_type = "reflection"
                operation = f"[{action}]"
                
                reminder = """
Please use one of these tags to indicate your action:

- **[THINK]** - Analyze the current situation and plan next steps
- **[CODE]** - Write Python/Pandas code to process data
- **[Final Answer]** - Provide your final answer to the question

What would you like to do next?
"""
                conversation_history.append(reminder)
            
            if "code" in task_type:
                pass
            else:
                self._emit_event(
                    name="excel_agent.task.done",
                    event_data={
                        "type": task_type,
                        "operation": operation,
                        "content": "<task_done>"
                    }
                )
        
        # è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œå¼ºåˆ¶ç»“æŸ
        print(f"\n{'='*60}")
        print(f"âš ï¸  Reached maximum iterations ({max_iterations})")
        print(f"{'='*60}")
        print(f"Forcing final answer extraction...")

        self._emit_event(
            name="excel_agent.task.start",
            event_data={
                "type": "reflection",
                "operation": f"[FORCE FINAL ANSWER]",
                "content": f"âš ï¸  Reached maximum iterations ({max_iterations})\nForcing final answer extraction...",
                "clean": True
            }
        )
        
        final_answer = self._force_extract_answer(
            conversation_history=conversation_history,
            current_df=current_df,
            user_query=user_query,
            table_metadata=table_metadata
        )

        self._emit_event(
            name="excel_agent.task.delta",
            event_data={
                "type": "reflection",
                "operation": f"[FORCE FINAL ANSWER]",
                "content": f"{final_answer}",
                "clean": True
            }
        )
        
        return {
            "final_df": current_df,
            "final_answer": final_answer,
            "execution_trace": execution_trace,
            "memory_nodes": self.memory,
            "iterations_used": max_iterations,
            "code_executions": code_executions,
            "success": False,  # è¶…æ—¶è¢«è¿«ç»“æŸ
            "reason": "max_iterations_reached"
        }
    
    def _build_initial_prompt(
        self,
        user_query: str,
        dataframe: pd.DataFrame,
        operator_sequence: List[str],
        operator_map: Dict[str, Operator],
        table_metadata: Dict[str, Any],
        schema_result=None
    ) -> str:
        """æ„å»ºåˆå§‹prompt"""
        
        # DataFrameä¿¡æ¯
        df_preview = dataframe.head(20).to_string()  # å‡å°‘åˆ°20è¡Œ
        df_shape = dataframe.shape
        df_columns = list(dataframe.columns)
        
        # Operatorå‚è€ƒä¿¡æ¯
        operator_reference = self._build_operator_reference(operator_sequence, operator_map)
        
        # Schemaä¿¡æ¯
        schema_hint = ""
        if schema_result and schema_result.selected_col_headers:
            schema_hint = f"""
## ğŸ¯ Schema Information (Relevant Headers)

**Relevant Columns** ({len(schema_result.selected_col_headers)}):
{', '.join(schema_result.selected_col_headers[:20])}

ğŸ’¡ These columns were identified as most relevant to the query.
"""
        
        # è¡¨æ ¼å…ƒæ•°æ®
        meta_hint = ""
        if table_metadata:
            meta_info = table_metadata.get("meta_info") or table_metadata
            if meta_info and not meta_info.get("error"):
                meta_lines = []
                meta_lines.append("\n## ğŸ“‹ Table Structure Information:")
                if "header_rows_skipped" in meta_info:
                    meta_lines.append(f"- Header rows skipped: {meta_info.get('header_rows_skipped', 0)}")
                    if meta_info.get('has_merged_cells'):
                        meta_lines.append("- âš ï¸  Merged cells preprocessed and expanded")
                meta_lines.append("- DataFrame `df` is clean and ready to use")
                meta_hint = "\n".join(meta_lines)
        
        prompt = f"""# Autonomous Code Generation Task

You are solving a tabular data question using an **autonomous iterative process**.

## ğŸ¯ Your Goal

Answer this question: **{user_query}**

## ğŸ“Š Available Data

**DataFrame Shape**: {df_shape[0]} rows Ã— {df_shape[1]} columns
**Columns**: {df_columns}

**Data Preview (first 20 rows)**:
```
{df_preview}
```
{schema_hint}
{meta_hint}

## ğŸ’¡ Reference Operator Sequence (from ADO)

The following operator sequence was suggested by our analysis module.
You can **follow** these steps or **deviate** based on your judgment.

{operator_reference}

âš ï¸ **Important**: This sequence is a REFERENCE, not a strict requirement.
You can:
- Follow these steps if they make sense
- Skip steps if unnecessary
- Add additional steps if needed
- Reorganize the order if beneficial

## ğŸ·ï¸ Action Tags You Can Use

At each iteration, indicate your action using one of these tags:

### 1. **[THINK]** or **[REFLECT]**
When you need to:
- Analyze the current situation and data structure
- Develop your analytical reasoning
- Plan your approach or reflect on results
- Draw insights from data patterns

**Quality over brevity**: Take 5-8 sentences to think thoroughly when needed.
Focus on deep analysis rather than just describing steps.

Example:
```
[THINK]
The question asks for equity analysis across categories. Looking at the data preview, 
I can see the distribution is highly skewed. The Gini coefficient measures inequality 
from 0 (perfect equality) to 1 (maximum inequality). Based on the visible values, 
top categories dominate the total. I should calculate group totals, compute the Gini, 
and identify concentration patterns. This will provide comprehensive inequality insights.
```

### 2. **[CODE]** (Optional - use only when truly needed)
Execute Python/Pandas code ONLY when:
- You need to process the full dataset (not just preview)
- Complex calculations are required
- Verification of computation is necessary

**Many questions can be answered through reasoning alone - code is not mandatory!**

Example:
```
[CODE]
```python
# Filter data
df = df[df['Year'] > 2020]
# Calculate sum
df = df.groupby('Category')['Value'].sum().reset_index()
```
```

**Critical code rules**:
- Use variable name `df` (already defined)
- Result MUST be assigned back to `df` as a DataFrame
- Use exact column names from the data
- Define all variables before use
- Use `round()` instead of format specifiers ({{:.2f}})

### 3. **[Final Answer]**
When you have the complete answer, provide a **detailed, well-structured response**.

**CRITICAL - Your final answer MUST follow the question's output format requirements**:
1. Use Markdown formatting (headers ##/###, lists, emphasis)
2. Present data in Markdown tables when appropriate
3. Include specific numerical results with proper context
4. Provide deep analysis and insights (not just numbers)
5. Give actionable, specific recommendations
6. For visualization questions: include complete Python code in ```python blocks

**Quality checklist for your final answer**:
- âœ… Comprehensive analysis (not superficial)
- âœ… Specific numerical evidence
- âœ… Interpretable insights and patterns
- âœ… Actionable recommendations (not vague suggestions)
- âœ… Professional formatting and structure

Example of HIGH-QUALITY final answer:
```
[Final Answer]

## Analysis Results

Based on comprehensive analysis of the dataset (N=500), here are the key findings:

### Summary Statistics
| Metric | Value | Interpretation |
|--------|-------|----------------|
| Mean | 45.2 | Above industry average |
| Std Dev | 12.3 | Moderate variability |

### Key Insights
1. **Trend Analysis**: The data shows a 23% increase over the period, indicating...
2. **Group Comparison**: Category A outperforms B by 2.5x (Cohen's d=0.82, large effect)

### Recommendations
1. **Prioritize Category A**: Given the strong performance and low variance, allocate 60% resources here
2. **Investigate Category C**: The declining trend (-15% YoY) requires immediate attention
3. **Optimize timing**: Peak occurs in Q2, suggesting seasonal strategy adjustment

[Include visualization code if requested]
```

## âš ï¸ OUTPUT FORMAT CONSTRAINTS

**CRITICAL**: Each iteration, you MUST output EXACTLY ONE action tag and its content. 

**Rules**:
1. Start your response directly with one of: `[THINK]`, `[CODE]`, or `[Final Answer]`
2. Do NOT add any extra text or explanation before the action tag
3. Do NOT add any extra text or explanation after the action content
4. Output ONLY the selected action and nothing else

**Correct format**:
```
[THINK]
<your reasoning>
```

**Incorrect format** (DO NOT do this):
```
Let me analyze this first.
[THINK]
<your reasoning>
I will code next.
```

## ğŸš€ Start Your Analysis

You have up to 10 iterations. Think carefully and decide your approach.

**Available Actions**:
- **[THINK]**: Deep analytical reasoning (5-8 sentences for complex problems)
- **[CODE]**: Execute Python code (optional - only when computation is truly needed)
- **[Final Answer]**: Provide comprehensive, well-formatted final answer

**Guidelines**:
- **Prioritize quality over speed**: Thorough analysis beats quick responses
- **Code is optional**: Many questions can be answered through reasoning alone
- **For simple questions**: You can directly provide [Final Answer] if confident
- **For analytical questions**: Use [THINK] to develop deep insights before answering
- **For complex calculations**: Use [CODE] only when necessary to process full dataset
- **Final answers must be detailed**: Include statistics, insights, and specific recommendations

**Remember**: Your goal is to provide high-quality, comprehensive answers that demonstrate deep understanding.

Begin now:
"""
        
        return prompt
    
    def _build_operator_reference(
        self,
        operator_sequence: List[str],
        operator_map: Dict[str, Operator]
    ) -> str:
        """æ„å»ºoperatorå‚è€ƒä¿¡æ¯"""
        
        lines = []
        lines.append("**Suggested Steps**:")
        
        for idx, op_name in enumerate(operator_sequence, 1):
            operator = operator_map.get(op_name)
            if operator:
                lines.append(f"\n{idx}. **{operator.name}**")
                lines.append(f"   Description: {operator.description}")
                lines.append(f"   Category: {operator.category.value}")
            else:
                lines.append(f"\n{idx}. **{op_name}** (details not available)")
        
        return "\n".join(lines)
    
    def _format_conversation(self, history: List[str]) -> str:
        """
        æ ¼å¼åŒ–å¯¹è¯å†å²
        ä¸ºäº†æ§åˆ¶prompté•¿åº¦å’ŒåŠ å¿«ç”Ÿæˆï¼Œåªä¿ç•™æœ€è¿‘çš„å…³é”®è½®æ¬¡
        """
        if len(history) <= 6:
            # å°‘äº6æ¡æ¶ˆæ¯ï¼Œå…¨éƒ¨ä¿ç•™
            return "\n\n".join(history)
        else:
            # ä¿ç•™åˆå§‹prompt + æœ€è¿‘5è½®å¯¹è¯
            initial_prompt = history[0]
            recent_history = history[-5:]
            return "\n\n".join([initial_prompt] + recent_history)
    
    def _parse_response_action(self, response: str) -> Tuple[str, str]:
        """
        è§£æresponseï¼Œè¯†åˆ«action
        
        Returns:
            (action_type, content)
            action_type: "THINK", "CODE", "FINAL_ANSWER", "UNKNOWN"
        """
        
        response_lower = response.lower()
        
        # æ£€æµ‹[Final Answer]
        if "[final answer]" in response_lower:
            return ("FINAL_ANSWER", response)
        
        # æ£€æµ‹[CODE]
        if "[code]" in response_lower:
            return ("CODE", response)
        
        # æ£€æµ‹[THINK]æˆ–[REFLECT]
        if "[think]" in response_lower or "[reflect]" in response_lower:
            return ("THINK", response)
        
        return ("UNKNOWN", response)
    
    def _extract_code_block(self, response: str) -> str:
        """ä»responseä¸­æå–ä»£ç å—"""
        
        # æ–¹æ³•1: æŸ¥æ‰¾[CODE]æ ‡ç­¾åçš„```pythonä»£ç å—
        pattern = r'\[CODE\]\s*```(?:python)?\s*(.*?)```'
        matches = re.findall(pattern, response, re.DOTALL | re.IGNORECASE)
        
        if matches:
            return matches[0].strip()
        
        # æ–¹æ³•2: æŸ¥æ‰¾ä»»æ„```pythonä»£ç å—
        pattern2 = r'```(?:python)?\s*(.*?)```'
        matches2 = re.findall(pattern2, response, re.DOTALL)
        
        if matches2:
            # å¦‚æœæœ‰å¤šä¸ªä»£ç å—ï¼Œåˆå¹¶å®ƒä»¬
            return '\n\n'.join(m.strip() for m in matches2)
        
        # æ–¹æ³•3: æŸ¥æ‰¾[CODE]ååˆ°ä¸‹ä¸€ä¸ªæ ‡ç­¾ä¹‹é—´çš„å†…å®¹
        pattern3 = r'\[CODE\](.*?)(?:\[THINK\]|\[REFLECT\]|\[Final Answer\]|$)'
        matches3 = re.findall(pattern3, response, re.DOTALL | re.IGNORECASE)
        
        if matches3:
            code = matches3[0].strip()
            # ç§»é™¤å¯èƒ½çš„markdownæ ‡è®°
            code = re.sub(r'^```(?:python)?\s*', '', code)
            code = re.sub(r'```\s*$', '', code)
            return code.strip()
        
        return ""
    
    def _extract_think_content(self, response: str) -> str:
        """æå–[THINK]æ ‡ç­¾çš„å†…å®¹"""
        
        pattern = r'\[THINK\](.*?)(?:\[CODE\]|\[Final Answer\]|$)'
        matches = re.findall(pattern, response, re.DOTALL | re.IGNORECASE)
        
        if matches:
            return matches[0].strip()
        
        pattern2 = r'\[REFLECT\](.*?)(?:\[CODE\]|\[Final Answer\]|$)'
        matches2 = re.findall(pattern2, response, re.DOTALL | re.IGNORECASE)
        
        if matches2:
            return matches2[0].strip()
        
        return response[:500]  # è¿”å›å‰500å­—ç¬¦ä½œä¸ºfallback
    
    def _extract_final_answer(self, response: str) -> str:
        """æå–[Final Answer]å†…å®¹"""
        
        pattern = r'\[Final Answer\]:?\s*(.*?)(?:\n\n\[|$)'
        matches = re.findall(pattern, response, re.DOTALL | re.IGNORECASE)
        
        if matches:
            answer = matches[0].strip()
            # å¦‚æœç­”æ¡ˆå¾ˆçŸ­ï¼Œå¯èƒ½æå–ä¸å®Œæ•´
            if len(answer) < 50:
                parts = response.split("[Final Answer]", 1)
                if len(parts) > 1:
                    answer = parts[1].strip()
                    answer = re.sub(r'^:\s*', '', answer)
            
            return f"{answer}"
        
        # Fallback: è¿”å›æ•´ä¸ªresponse
        return response
    
    def _execute_code_safe(self, code: str, df: pd.DataFrame) -> Dict[str, Any]:
        """å®‰å…¨æ‰§è¡Œä»£ç """
        
        import numpy as np
        
        if not code:
            return {"success": False, "error": "Empty code"}
        
        # å®‰å…¨æ£€æŸ¥
        forbidden = ["exit(", "quit(", "sys.exit", "os.system", "subprocess", 
                     "__import__", "eval(", "exec(", "open("]
        for kw in forbidden:
            if kw in code:
                return {"success": False, "error": f"Forbidden keyword: {kw}"}
        
        # å‡†å¤‡æ‰§è¡Œç¯å¢ƒ
        try:
            df_copy = df.copy()
        except:
            df_copy = df
        
        local_vars = {
            "df": df_copy,
            "pd": pd,
            "np": np
        }
        
        global_vars = {
            "pd": pd,
            "np": np,
            "__builtins__": __builtins__
        }
        
        # æ‰§è¡Œ
        try:
            exec(code, global_vars, local_vars)
            result_df = local_vars.get("df", df)
            
            # è‡ªåŠ¨è½¬æ¢dictä¸ºDataFrame
            if isinstance(result_df, dict):
                try:
                    result_df = pd.DataFrame(result_df)
                    print(f"    â„¹ï¸  Auto-converted dict to DataFrame")
                except Exception as e:
                    return {
                        "success": False,
                        "error": f"Result is dict but cannot convert to DataFrame: {e}",
                        "dataframe": df
                    }
            
            # ç¡®ä¿æ˜¯DataFrame
            if not isinstance(result_df, pd.DataFrame):
                return {
                    "success": False,
                    "error": f"Result must be DataFrame, got {type(result_df).__name__}",
                    "dataframe": df
                }
            
            return {
                "success": True,
                "dataframe": result_df,
                "error": None
            }
        
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "dataframe": df
            }
    
    def _build_success_feedback(self, exec_result: Dict, result_df: pd.DataFrame) -> str:
        """æ„å»ºæˆåŠŸæ‰§è¡Œçš„åé¦ˆ"""
        
        preview = result_df.head(20).to_string()
        
        feedback = f"""
## âœ… Code Execution Successful!

**Result Summary**:
- Shape: {result_df.shape[0]} rows Ã— {result_df.shape[1]} columns
- Columns: {list(result_df.columns)}

**Result Preview (first 20 rows)**:
```
{preview}
```

---

**What's your next step?**
- Use **[THINK]** to deeply analyze these results and draw insights
- Use **[CODE]** if you need additional computation (optional)
- Use **[Final Answer]** if you can now provide a comprehensive, detailed answer
"""
        
        return feedback
    
    def _build_error_feedback(self, exec_result: Dict) -> str:
        """æ„å»ºå¤±è´¥æ‰§è¡Œçš„åé¦ˆ"""
        
        error_msg = exec_result.get("error", "Unknown error")
        
        feedback = f"""
## âŒ Code Execution Failed

**Error Message**:
```
{error_msg}
```

---

**Please use [THINK] to:**
1. Analyze what went wrong
2. Understand the root cause
3. Plan how to fix it

Then use **[CODE]** to try again with corrected code.
"""
        
        return feedback
    
    def _force_extract_answer(
        self,
        conversation_history: List[str],
        current_df: pd.DataFrame,
        user_query: str,
        table_metadata: Dict[str, Any] = None
    ) -> str:
        """è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œå¼ºåˆ¶æå–ç­”æ¡ˆ"""
        
        # å°è¯•ä»æœ€åå‡ è½®ä¸­æå–æœ‰ç”¨ä¿¡æ¯
        recent_history = "\n\n".join(conversation_history[-5:])  # å¢åŠ åˆ°æœ€å5è½®
        
        # æ„å»ºè¡¨æ ¼metadataä¿¡æ¯
        meta_info_str = ""
        if table_metadata:
            meta_info = table_metadata.get("meta_info") or table_metadata
            if meta_info and not meta_info.get("error"):
                meta_info_str = "\n## ğŸ“‹ Table Metadata\n"
                if "header_rows_skipped" in meta_info:
                    meta_info_str += f"- Header rows skipped: {meta_info.get('header_rows_skipped', 0)}\n"
                if meta_info.get('has_merged_cells'):
                    meta_info_str += "- Merged cells were preprocessed\n"
                if "total_rows" in meta_info:
                    meta_info_str += f"- Original total rows: {meta_info.get('total_rows')}\n"
        
        # æ„å»ºå¼ºåˆ¶æå–prompt
        force_prompt = f"""
You've reached the iteration limit. Please provide your **COMPREHENSIVE final answer NOW** based on all the work done.

## Original Question
{user_query}

## Current DataFrame State
Shape: {current_df.shape}
Columns: {list(current_df.columns)}
{meta_info_str}

Preview (first 20 rows):
{current_df.head(20).to_string()}

## Recent History (last 5 interactions)
{recent_history[:3000]}

---

**CRITICAL: Provide a HIGH-QUALITY [Final Answer] that includes:**

1. **Specific numerical results**: Include all relevant statistics, calculations, and metrics
2. **Deep analysis**: Explain patterns, trends, and what the numbers mean
3. **Clear insights**: What are the key takeaways and implications?
4. **Actionable recommendations**: Specific, feasible suggestions (not vague advice)
5. **Professional formatting**: Use Markdown headers, tables, lists appropriately
6. **Visualization code**: If the question asks for charts, include complete Python code

**Your answer should demonstrate:**
- Thoroughness (comprehensive coverage of all aspects)
- Depth (insightful analysis, not just surface-level description)
- Clarity (well-organized, easy to understand)
- Utility (actionable and practical)

Use this format:
[Final Answer]
<your detailed, comprehensive answer here>
"""
        
        try:
            response = self.llm_client.call_api(force_prompt, max_tokens=4096)
            return self._extract_final_answer(response)
        except Exception as e:
            print(f"âŒ Force extraction failed: {e}")
            # Fallback: åŸºäºDataFrameç”Ÿæˆç®€å•ç­”æ¡ˆ
            if current_df.empty:
                return "[Final Answer]: No data available to answer the question."
            else:
                return f"[Final Answer]: Based on the processed data (shape: {current_df.shape}), here are the results:\n{current_df.head(10).to_string()}"
    
    def get_memory_summary(self) -> Dict[str, Any]:
        """è·å–å†…å­˜æ‘˜è¦"""
        if not self.memory:
            return {
                "total_nodes": 0,
                "success_rate": 0.0,
                "avg_reward": 0.0
            }
        
        success_count = sum(1 for node in self.memory if node.success)
        
        return {
            "total_nodes": len(self.memory),
            "success_count": success_count,
            "failure_count": len(self.memory) - success_count,
            "success_rate": success_count / len(self.memory) if self.memory else 0.0
        }
    
    def clear_memory(self):
        """æ¸…ç©ºå†…å­˜"""
        self.memory = []
